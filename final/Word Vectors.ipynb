{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fooling with Word Vectors ##\n",
    "https://github.com/aparrish/rwet/blob/master/understanding-word-vectors.ipynb\n",
    "\n",
    "https://github.com/aparrish/rwet/blob/master/understanding-word-vectors.ipynb\n",
    "\n",
    "In order to get some of my Dark Souls objects to rhyme I'll have to learn Word Vectors.\n",
    "\n",
    "Word Vectors are distance relationships (their *Euclidean distance*) between points. These points can be words and their attributes. \n",
    "\n",
    "Here's some basic arithmetic function. \n",
    ">(The ** operator raises the value on its left to the power on its right.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def distance2d(x1, y1, x2, y2):\n",
    "    return math.sqrt((x1 -x2)**2 + (y1 - y2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.180339887498949"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance2d(70, 30, 75, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_data = json.loads(open(\"xkcd.json\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will convert the color from the hex format to a tuple of integers - hence the \"#\" (#1a2b3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hex_to_int(s):\n",
    "    s = s.lstrip(\"#\")\n",
    "    return int(s[:2], 16), int(s[2:4], 16), int(s[4:6],16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will create a dictionary and populate it with mapping from color names to RGB\n",
    "\n",
    "\"Color\", \"Colors\" and \"Hex\" relates to how the xkcd.json file is organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = dict()\n",
    "for item in color_data['colors']:\n",
    "    colors[item[\"color\"]] = hex_to_int(item[\"hex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 117, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors['olive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the functions that allow for Vector arithmetic to find distances between points in several dimensions (trippy!)\n",
    "\n",
    "Tried on paper...using a ruler. Math still works. Here's what's happening: √(x2-x1)²+(y2-y1)²\n",
    "\n",
    "No idea what's the \"zip\" for though...\n",
    "\n",
    "**Distance between points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(coord1, coord2):\n",
    "    # VERY SLOW - use for learning purposed only!\n",
    "    return math.sqrt(sum([(i-j)**2 for i, j in zip(coord1, coord2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance([10,1], [5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subtract Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subtractv (coord1, coord2):\n",
    "    return [c1 - c2 for c1, c2 in zip (coord1, coord2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, -1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtractv([10,1],[5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addv(coord1, coord2):\n",
    "    return[c1 + c2 for c1, c2 in zip(coord1, coord2)]\n",
    "addv([10,1], [5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average between a list of vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 2.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def meanv(coords):\n",
    "    sumv = [0] * len(coords[0])\n",
    "    for item in coords:\n",
    "        for i in range(len(item)):\n",
    "            sumv[i] += item[i]\n",
    "    mean = [0] * len(sumv)\n",
    "    for i in range(len(sumv)):\n",
    "        mean[i] = float(sumv[i]) / len(coords)\n",
    "    return mean\n",
    "meanv([[0, 1], [2, 2], [4, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241.4415043028021"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(colors['red'], colors['dark pastel green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(colors['blue'], colors['green']) > distance(colors['red'], colors['pink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors in spaCY ##\n",
    "\n",
    "The xkcd.json example dealt with colors that were already organized as a numbered matrix (don't even know if this makes sense, but bear with me). But words are not so easily related. The number of dimensions vary imensily and change depending on methodology. \n",
    "\n",
    "Allison recommends in her tutorial to go straight to using spaCy. This program uses **GloVe** - Stanford's ready made (trained) word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-72-99e161da019a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-72-99e161da019a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    file = open((\"frankenstein.txt\", encoding=\"utf8\").read())\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "file = open(filename, encoding=\"utf8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(open(\"frankenstein.txt\", encoding=\"utf8\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbed frankenstein (84-0.txt) from the gutenberg page, renamed it and ran using the \", encoding=\"utf8\" command - Withouth the charset I had errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add all the words in the text file\n",
    "tokens = list(set([w.text for w in doc if w.is_alpha]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.65439987e-01,  -4.81970012e-01,   4.41280007e-01,\n",
       "        -6.79279983e-01,   4.23440002e-02,  -2.80189998e-02,\n",
       "        -7.59750009e-02,  -7.15219975e-01,  -4.24109995e-01,\n",
       "         1.94410002e+00,  -1.21140003e-01,  -8.99289995e-02,\n",
       "        -5.72640002e-01,   2.53939986e-01,   1.99970007e-01,\n",
       "         5.26599996e-02,   3.35750014e-01,   1.71739995e+00,\n",
       "        -4.35149997e-01,   2.17390001e-01,   2.21090000e-02,\n",
       "        -6.64120018e-02,  -3.66420001e-01,  -4.11419988e-01,\n",
       "        -2.00049996e-01,  -5.14129996e-01,   1.52140006e-01,\n",
       "         2.87669986e-01,   1.59429997e-01,   5.04710019e-01,\n",
       "        -4.47310001e-01,   8.42199981e-01,  -4.75209989e-02,\n",
       "        -2.90859997e-01,  -2.70959996e-02,  -5.63480020e-01,\n",
       "        -7.71640018e-02,   1.10760003e-01,   2.30910003e-01,\n",
       "        -5.79890013e-01,   1.91699993e-02,  -2.47799993e-01,\n",
       "         2.84900010e-01,  -1.42419994e-01,   1.33900002e-01,\n",
       "         3.67000014e-01,   2.31389999e-01,   1.47330001e-01,\n",
       "        -2.69219995e-01,  -3.79740000e-02,   1.32349998e-01,\n",
       "         2.81109996e-02,   3.65379989e-01,   5.64360023e-01,\n",
       "         5.39910011e-02,   1.34800002e-01,   1.93200007e-01,\n",
       "         7.48319983e-01,  -1.48220003e-01,  -8.49619985e-01,\n",
       "        -2.47390002e-01,  -1.40039995e-01,   2.96020001e-01,\n",
       "         2.26689994e-01,  -1.89300001e-01,   5.87509990e-01,\n",
       "         1.48819998e-01,   3.73189986e-01,   2.24020004e-01,\n",
       "         5.17069995e-02,   2.28860006e-01,  -4.77690011e-01,\n",
       "        -5.47100008e-01,  -2.18940005e-01,  -4.78650004e-01,\n",
       "        -6.43540025e-02,  -1.21390000e-01,  -1.87950000e-01,\n",
       "        -3.94010007e-01,   3.21790010e-01,  -3.84499997e-01,\n",
       "        -7.50180036e-02,   1.51060000e-01,  -1.55469999e-01,\n",
       "        -2.24179998e-01,   4.03690010e-01,  -3.42280000e-01,\n",
       "         7.32949972e-02,  -3.92639995e-01,  -5.91190010e-02,\n",
       "        -5.77390015e-01,  -2.85070002e-01,  -3.48859996e-01,\n",
       "         3.29789996e-01,   1.63770005e-01,  -7.18890011e-01,\n",
       "         5.32760024e-01,   3.09069991e-01,  -4.72779982e-02,\n",
       "         1.75500005e-01,  -8.53730023e-01,   8.49969983e-02,\n",
       "        -1.01099998e-01,   1.64030001e-01,  -5.49309999e-02,\n",
       "        -9.58010018e-01,   1.04269996e-01,   5.48280001e-01,\n",
       "         5.69270015e-01,  -6.30659983e-02,   2.54999995e-02,\n",
       "         3.20930004e-01,   4.19499993e-01,  -1.75750002e-01,\n",
       "        -8.86259973e-02,   1.62479997e-01,   1.38109997e-01,\n",
       "         3.01250011e-01,  -2.89149992e-02,  -1.86230000e-02,\n",
       "         2.88269997e-01,  -2.25850001e-01,   1.19159997e-01,\n",
       "         3.53509992e-01,   2.83360004e-01,  -1.77699998e-02,\n",
       "        -3.72229993e-01,  -2.68310010e-01,  -2.32270006e-02,\n",
       "        -8.31860006e-02,  -3.93689990e-01,   4.21420008e-01,\n",
       "        -6.40019998e-02,  -2.34999999e-01,   2.38049999e-02,\n",
       "         4.52910006e-01,   2.30700001e-01,  -2.07530007e-01,\n",
       "         9.60040018e-02,   2.29379997e-01,  -1.43910003e+00,\n",
       "        -5.83280027e-01,  -2.37650007e-01,  -1.43820003e-01,\n",
       "        -3.69560003e-01,   1.09609999e-01,   6.89040005e-01,\n",
       "        -4.64340001e-01,  -6.52930021e-01,  -1.78110003e-01,\n",
       "         1.28600001e-01,   5.94430007e-02,   1.46899998e-01,\n",
       "         3.48600000e-01,   6.25790000e-01,  -5.42940021e-01,\n",
       "         3.27580012e-02,  -2.04129994e-01,   2.17749998e-01,\n",
       "         6.07709996e-02,  -9.13629979e-02,  -4.22479987e-01,\n",
       "        -6.77209999e-03,  -4.56670008e-04,   6.72270000e-01,\n",
       "        -3.07729989e-01,  -5.31970002e-02,  -2.03740001e-01,\n",
       "        -1.94470003e-01,  -7.70850033e-02,  -2.70040005e-01,\n",
       "        -5.09459972e-01,  -1.12340003e-01,   4.02990013e-01,\n",
       "        -4.04989988e-01,   8.53549987e-02,   5.09269983e-02,\n",
       "         5.06500006e-01,  -4.06109989e-01,   6.20190017e-02,\n",
       "         2.23130003e-01,  -4.79659997e-02,  -3.99909988e-02,\n",
       "        -3.63909990e-01,  -2.25639999e-01,  -3.26000005e-01,\n",
       "        -2.64550000e-01,   3.49460006e-01,   1.81659997e-01,\n",
       "         1.44040003e-01,  -9.05629992e-01,   2.23299995e-01,\n",
       "        -3.16130012e-01,  -3.22000012e-02,  -5.05089983e-02,\n",
       "         7.05709979e-02,  -1.10840000e-01,  -4.25199986e-01,\n",
       "         3.30579996e-01,  -4.08769995e-01,  -2.98290014e-01,\n",
       "        -7.87779987e-02,  -1.77860007e-01,  -3.90130013e-01,\n",
       "        -1.68320000e-01,  -1.61180004e-01,   1.94710001e-01,\n",
       "         3.52459997e-01,   2.23830000e-01,  -1.44290000e-01,\n",
       "         2.26989999e-01,  -2.65269995e-01,  -3.02810013e-01,\n",
       "         3.75880003e-01,   6.48050010e-02,   2.02140003e-01,\n",
       "        -1.09159999e-01,   1.15620002e-01,  -3.59389991e-01,\n",
       "         4.42490011e-01,  -2.49109998e-01,   1.21059999e-01,\n",
       "         3.35999995e-01,  -1.98650006e-02,   4.29109991e-01,\n",
       "         1.96140006e-01,   1.73419997e-01,   3.04439992e-01,\n",
       "         2.32149996e-02,   6.27099991e-01,  -1.78819999e-01,\n",
       "        -5.33559978e-01,  -6.23939991e-01,   4.53330010e-01,\n",
       "        -8.31489980e-01,  -2.00220004e-01,  -3.49460006e-01,\n",
       "        -2.22589999e-01,   6.48080036e-02,  -2.78069992e-02,\n",
       "         4.97500002e-01,   9.92130022e-03,   1.32220000e-01,\n",
       "        -1.09250002e-01,   6.24679998e-02,  -4.40869987e-01,\n",
       "        -3.30119997e-01,  -6.67840019e-02,   5.69770001e-02,\n",
       "         1.38150007e-01,   1.29130006e-01,  -3.41810007e-03,\n",
       "        -1.92850009e-02,   1.49560004e-01,   4.39909995e-01,\n",
       "        -1.91599995e-01,   7.48500004e-02,  -5.62900007e-01,\n",
       "         6.33540004e-02,  -4.03010011e-01,   4.52540010e-01,\n",
       "        -1.98589996e-01,   3.41580003e-01,  -2.40109991e-02,\n",
       "        -3.37170005e-01,  -3.20380002e-01,  -1.45050004e-01,\n",
       "         2.54710000e-02,   4.63440008e-02,  -2.87699997e-01,\n",
       "         5.25249988e-02,   1.56049997e-01,  -2.60300010e-01,\n",
       "        -2.19710007e-01,  -1.10689998e-01,  -2.14460000e-01,\n",
       "         5.23599982e-02,   1.13899998e-01,   2.84720004e-01,\n",
       "        -5.49640000e-01,   4.07620013e-01,   2.57230014e-01,\n",
       "         2.74820000e-01,  -1.29429996e-01,   3.86000007e-01,\n",
       "        -3.57549995e-01,   2.16969997e-01,  -6.82810023e-02,\n",
       "        -6.36930019e-02,  -4.03169990e-02,   4.58990008e-01,\n",
       "         2.11679995e-01,  -1.02650002e-01,   5.98420024e-01,\n",
       "         9.16569978e-02,   2.46209994e-01,  -6.71759993e-02,\n",
       "         2.95390010e-01,  -3.83500010e-02,  -2.15110004e-01], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['master'].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates a function that gets the vector of a given string from spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(s): \n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.vec>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity and closest neighbors ##\n",
    "consine() returns cosine similarity of two vector. This is another way to see similarities \"more suited to hight-dimensional spaces\", like all the words in Frankenstein.\n",
    "\n",
    "**Have to install numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1,v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(vec('human'), vec('person')) > cosine(vec('dog'), vec ('peace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_closest(token_list, vec_to_check, n=10):\n",
    "    return sorted(token_list,\n",
    "                 key=lambda x: cosine(vec_to_check, vec(x)),\n",
    "                 reverse=True) [:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth',\n",
       " 'faith',\n",
       " 'believing',\n",
       " 'belief',\n",
       " 'true',\n",
       " 'believe',\n",
       " 'Believe',\n",
       " 'reality',\n",
       " 'nothing',\n",
       " 'Nothing']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_closest(tokens, vec(\"truth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the halfway point between two words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['war',\n",
       " 'truth',\n",
       " 'nothing',\n",
       " 'Nothing',\n",
       " 'Fear',\n",
       " 'fear',\n",
       " 'strife',\n",
       " 'conflict',\n",
       " 'wars',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_closest(tokens, meanv([vec(\"truth\"), vec(\"war\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['men',\n",
       " 'Men',\n",
       " 'women',\n",
       " 'business',\n",
       " 'Among',\n",
       " 'among',\n",
       " 'market',\n",
       " 'professional',\n",
       " 'opportunities',\n",
       " 'employees']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_to_sky = subtractv(vec(\"men\"), vec(\"god\"))\n",
    "spacy_closest(tokens, addv(blue_to_sky, vec(\"industry\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blue_to_sky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing with tracery ##\n",
    "\n",
    "I'll try to mix what I've done with Tracery rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tracery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "closest_truWar = spacy_closest(tokens, meanv([vec(\"truth\"), vec(\"war\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (closest_truWar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strife'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_truWar[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-9b9ea3fc1c78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"When will you ever see\"\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mclosest_truWar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When will you ever see war\n",
      "When will you ever see truth\n",
      "When will you ever see nothing\n",
      "When will you ever see Nothing\n",
      "When will you ever see Fear\n",
      "When will you ever see fear\n",
      "When will you ever see strife\n",
      "When will you ever see conflict\n",
      "When will you ever see wars\n",
      "When will you ever see humanity\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-cafa55310178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"When will you ever see\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m+\u001b[0m  \u001b[0mclosest_truWar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(20):  \n",
    "    print (\"When will you ever see\" + \" \"+  closest_truWar[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Dark Souls JSON libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "darksouls_data = json.loads(open(\"darksouls_edit.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = darksouls_data['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creatures = words['creatures']\n",
    "objects = words['objects']\n",
    "techniques = words['techniques']\n",
    "actions = words['actions']\n",
    "techniques = words['techniques']\n",
    "actions = words['actions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bodyParts = words['body parts']\n",
    "attributes = words['attribute']\n",
    "concepts = words['concepts']\n",
    "adverbs = json.loads(open(\"adverbs.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adverbsList = json.loads(open(\"adverbs.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbsLove = json.loads(open(\"verbsLove.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adverbs = adverbsList[\"adverbs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = verbsLove['verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunctions = [\n",
    "\n",
    "\"when\",\n",
    "\"once\",\n",
    "\"as soon as\",\n",
    "\"if\",\n",
    "\"till\",\n",
    "\"untill\",\n",
    "\"provided that\",\n",
    "\"unless\",\n",
    "\"even though\",\n",
    "\"although\",\n",
    "\"as\",\n",
    "\"because\",\n",
    "\"after\",\n",
    "\"before\",\n",
    "\"in spite of\",\n",
    "\"despite\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "moods_list = json.loads(open(\"moods_data.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moods = moods_list['moods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations_list = json.loads(open(\"locations_data.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = locations_list['locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One evening in Church of Yorshka, a envious queen met a herald who asked: Do you believe that a charmer can love a queen?\n",
      "The herald looked at the queen with a loving left leg and touched the queen's thumb while saying:\n",
      "Only when a sellsword has his or her right leg closely kissed by a beanpole, will a charmer truly believe in love.\n",
      "One evening in Ariandel, a unconcerned beggar met a god who asked: Do you believe that a dwarf can love a beggar?\n",
      "The god looked at the beggar with an excluded anywhere and touched the beggar's stomach while saying:\n",
      "Only when an artisan has his or her head painfully rubbed by an artisan, will a dwarf truly believe in love.\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\":[\"#[lover:#creature#][wise:#creature#][muse:#creature#]story#\"],\n",
    "    \n",
    "    \"story\": [\"One evening in #location#, a #mood# #lover# met #wise.a# who asked: Do you believe that #muse.a# can love #lover.a#?\\nThe #wise# looked at the #lover# with #mood.a# #bodyPart# and touched the #lover#'s #bodyPart# while saying:\\nOnly when #creature.a# has his or her #bodyPart# #adverb# #verb# by #creature.a#, will #muse.a# truly believe in love.\"],\n",
    "   \n",
    "    \"noun\": [ \"#creature#\", \"#bodyPart#\", \"#concept#\", \"#object#\"],\n",
    "    \n",
    "\"verb\": verbs,\n",
    "\"location\" : locations,\n",
    "\"object\": objects,\n",
    "\"creature\": creatures,\n",
    "\"bodyPart\": bodyParts,\n",
    "\"action\": actions,\n",
    "\"concept\": concepts,\n",
    "\"conjunction\": conjunctions,\n",
    "\"adverb\": adverbs,\n",
    "\"mood\" : moods\n",
    "\n",
    "}\n",
    "    \n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "for i in range(2): \n",
    "    print(grammar.flatten(\"#origin#\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding word vectors to Tracery code ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One evening in Ariandel, a useless laggard met an ally who asked: Do you believe that a bug can love a laggard?\n",
      "The ally looked at the laggard with an accomplished arm and touched the laggard's tail while saying:\n",
      "Only when a Dark Spirit has his or her core carefully caressed by a saint, will a bug truly believe in love.\n",
      "One evening in Grand Archives, a irked bug met a dragon who asked: Do you believe that a cleric can love a bug?\n",
      "The dragon looked at the bug with a deprived left arm and touched the bug's right arm while saying:\n",
      "Only when a dwarf has his or her ringfinger joyously caressed by a Hollow, will a cleric truly believe in love.\n",
      "bug\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fix',\n",
       " 'problem',\n",
       " 'patches',\n",
       " 'pest',\n",
       " 'insect',\n",
       " 'errors',\n",
       " 'fixed',\n",
       " 'annoying',\n",
       " 'worm',\n",
       " 'code']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\":[\"#[lover:#creature#][wise:#creature#][muse:#creature#]story#\"],\n",
    "    \n",
    "    \"story\": [\"One evening in #location#, a #mood# #lover# met #wise.a# who asked: Do you believe that #muse.a# can love #lover.a#?\\nThe #wise# looked at the #lover# with #mood.a# #bodyPart# and touched the #lover#'s #bodyPart# while saying:\\nOnly when #creature.a# has his or her #bodyPart# #adverb# #verb# by #creature.a#, will #muse.a# truly believe in love.\"],\n",
    "   \n",
    "    \"noun\": [ \"#creature#\", \"#bodyPart#\", \"#concept#\", \"#object#\"],\n",
    "    \n",
    "\"verb\": verbs,\n",
    "\"location\" : locations,\n",
    "\"object\": objects,\n",
    "\"creature\": creatures,\n",
    "\"bodyPart\": bodyParts,\n",
    "\"action\": actions,\n",
    "\"concept\": concepts,\n",
    "\"conjunction\": conjunctions,\n",
    "\"adverb\": adverbs,\n",
    "\"mood\" : moods\n",
    "\n",
    "}\n",
    "    \n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "for i in range(2): \n",
    "    print(grammar.flatten(\"#origin#\"))\n",
    "    \n",
    "print(grammar.flatten(\"#lover#\"))\n",
    "spacy_closest(tokens, vec(grammar.flatten(\"#lover#\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy_tracery_closest = spacy_closest(tokens, vec(grammar.flatten(\"#lover#\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fix'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tracery_closest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediately.......One evening in Road of Sacrifices , a energetic good fellow met a sniper who asked: Do you believe that a fatty can love a good fellow?\n",
      "The sniper looked at the good fellow with an outraged core and touched the good fellow's longfinger while saying:\n",
      "Only when a moneybags has his or her left leg neatly rubbed by an ally, will a fatty truly believe in love.\n",
      " The good fellow looked at a mirror and saw an ages and a youth and a Child...\n",
      " Not a single fatty, only bummed Agrippa and a deathlike and a Leeuw \n",
      "good fellow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['complexions',\n",
       " 'nourishment',\n",
       " 'diet',\n",
       " 'muscle',\n",
       " 'unwholesome',\n",
       " 'wholesome',\n",
       " 'lean',\n",
       " 'excess',\n",
       " 'eat',\n",
       " 'milk']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\":[\"#[lover:#creature#][wise:#creature#][muse:#creature#]story#\"],\n",
    "    \n",
    "    \"story\": [\"#tracery_halfsies#.......One evening in #location#, a #mood# #lover# met #wise.a# who asked: Do you believe that #muse.a# can love #lover.a#?\\nThe #wise# looked at the #lover# with #mood.a# #bodyPart# and touched the #lover#'s #bodyPart# while saying:\\nOnly when #creature.a# has his or her #bodyPart# #adverb# #verb# by #creature.a#, will #muse.a# truly believe in love.\\n The #lover# looked at a mirror and saw #tracery_lover.a# and #tracery_lover.a# and #tracery_lover.a#...\\n Not a single #muse#, only #mood# #tracery_muse# and #tracery_muse.a# and #tracery_muse.a# \"],\n",
    "   \n",
    "    \"noun\": [ \"#creature#\", \"#bodyPart#\", \"#concept#\", \"#object#\"],\n",
    "    \n",
    "\"verb\": verbs,\n",
    "\"location\" : locations,\n",
    "\"object\": objects,\n",
    "\"creature\": creatures,\n",
    "\"bodyPart\": bodyParts,\n",
    "\"action\": actions,\n",
    "\"concept\": concepts,\n",
    "\"conjunction\": conjunctions,\n",
    "\"adverb\": adverbs,\n",
    "\"mood\" : moods,\n",
    "\n",
    "\"tracery_lover\": spacy_closest(tokens, vec(grammar.flatten(\"#lover#\"))),\n",
    "\"tracery_muse\": spacy_closest(tokens, vec(grammar.flatten(\"#muse#\"))),\n",
    "\"tracery_halfsies\": spacy_closest(tokens, meanv([vec(\"#lover#\"), vec(\"#muse#\")]))\n",
    "}\n",
    "    \n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "for i in range(1): \n",
    "    print(grammar.flatten(\"#origin#\"))\n",
    "    \n",
    "print(grammar.flatten(\"#lover#\"))\n",
    "spacy_closest(tokens, vec(grammar.flatten(\"#lover#\")))\n",
    "\n",
    "spacy_closest(tokens, vec(grammar.flatten(\"#muse#\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lover',\n",
       " 'lovers',\n",
       " 'playmate',\n",
       " 'Friend',\n",
       " 'friend',\n",
       " 'husband',\n",
       " 'kiss',\n",
       " 'lady',\n",
       " 'girl',\n",
       " 'caresses']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_closest(tokens, vec(grammar.flatten(\"lover\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
